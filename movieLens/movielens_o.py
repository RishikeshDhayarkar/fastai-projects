# -*- coding: utf-8 -*-
"""movieLens_o.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K6mpQ0HcPFpwG2dmBrcoKkeQMhwRB1Y4
"""

pip install fastai==0.7.0

pip install torchvision==0.1.9

pip install torch==0.4.1

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

from fastai.learner import *

from fastai.column_data import *

from google.colab import drive
drive.mount('/content/drive')

path_ratings='/content/drive/My Drive/ml-latest-small/ratings.csv'

ratings = pd.read_csv(path_ratings)

ratings.head()

g = ratings.groupby('userId')['rating'].count()

g

topUsers = g.sort_values(ascending=False)[:15]

topUsers

g = ratings.groupby('movieId')['rating'].count()

topMovies = g.sort_values(ascending=False)[:15]

topMovies

top_r = ratings.join(topUsers, rsuffix='_r', how='inner', on='userId')
top_r = top_r.join(topMovies, rsuffix='_r', how='inner', on='movieId')

pd.crosstab(top_r.userId, top_r.movieId, top_r.rating, aggfunc=np.sum)

val_idxs = get_cv_idxs(len(ratings))

wd=2e-4
n_factors = 50

path ='/content/drive/My Drive/ml-latest-small'

cf = CollabFilterDataset.from_csv(path, 'ratings.csv', 'userId', 'movieId', 'rating')

learn = cf.get_learner(n_factors, val_idxs, 64, opt_fn=optim.Adam)

val_idxs

learn.fit(1e-2, 2, wds=wd, cycle_len=1, cycle_mult=2)

math.sqrt(0.735)

"""RMSE = 0.857. Benchmark RMSE = 0.91"""

preds = learn.predict()

y=learn.data.val_y
sns.jointplot(preds, y, kind='hex', stat_func=None);

m=learn.model; m.cuda()

"""Modelling from scratch

Dot product implementation
"""

a = T([[1.,2],[3,4]])
b = T([[2.,2],[10,10]])
a,b

a*b

(a*b).sum(1)

class DotProduct(nn.Module):
  def forward(self, u, m):
    return (u*m).sum(1)

myModel = DotProduct()

myModel.forward(a,b)

"""Dot product model"""

u_uniq = ratings.userId.unique()

user2idx = {o:i for i,o in enumerate(u_uniq)}

ratings.userId = ratings.userId.apply(lambda x: user2idx[x])

ratings

m_uniq = ratings.movieId.unique()
movie2idx = {o:i for i,o in enumerate(m_uniq)}
ratings.movieId = ratings.movieId.apply(lambda x: movie2idx[x])

ratings

n_users=int(ratings.userId.nunique())
n_movies=int(ratings.movieId.nunique())

n_users,n_movies

cf.n_users

cf.n_items

class EmbeddingDot(nn.Module):
    def __init__(self, n_users, n_movies):
        super().__init__()
        self.u = nn.Embedding(n_users, n_factors)
        self.m = nn.Embedding(n_movies, n_factors)
        self.u.weight.data.uniform_(0,0.05)
        self.m.weight.data.uniform_(0,0.05)
        
    def forward(self, cats, conts):
        users,movies = cats[:,0],cats[:,1]
        u,m = self.u(users),self.m(movies)
        return (u*m).sum(1).view(-1, 1)

x = ratings.drop(['rating', 'timestamp'],axis=1)
y = ratings['rating'].astype(np.float32)

x

y

data = ColumnarModelData.from_data_frame(path, val_idxs, x, y, ['userId', 'movieId'], 64)

wd=1e-5
model = EmbeddingDot(n_users, n_movies).cuda()
opt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)

fit(model, data, 3, opt, F.mse_loss)

set_lrs(opt, 0.01)

fit(model, data, 3, opt, F.mse_loss)

"""Add Bias to the model"""

min_rating,max_rating = ratings.rating.min(),ratings.rating.max()
min_rating,max_rating

def get_emb(ni,nf):
    e = nn.Embedding(ni, nf)
    e.weight.data.uniform_(-0.01,0.01)
    return e

class EmbeddingDotBias(nn.Module):
    def __init__(self, n_users, n_movies):
        super().__init__()
        (self.u, self.m, self.ub, self.mb) = [get_emb(*o) for o in [
            (n_users, n_factors), (n_movies, n_factors), (n_users,1), (n_movies,1)
        ]]
        
    def forward(self, cats, conts):
        users,movies = cats[:,0],cats[:,1]
        um = (self.u(users)* self.m(movies)).sum(1)
        res = um + self.ub(users).squeeze() + self.mb(movies).squeeze()
        res = F.sigmoid(res) * (max_rating-min_rating) + min_rating
        return res.view(-1, 1)

wd=2e-4
model = EmbeddingDotBias(cf.n_users, cf.n_items).cuda()
opt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)

fit(model, data, 3, opt, F.mse_loss)

set_lrs(opt, 1e-2)

fit(model, data, 3, opt, F.mse_loss)

"""Creating a neural net"""

class EmbeddingNet(nn.Module):
    def __init__(self, n_users, n_movies, nh=10, p1=0.05, p2=0.5):
        super().__init__()
        (self.u, self.m) = [get_emb(*o) for o in [
            (n_users, n_factors), (n_movies, n_factors)]]
        self.lin1 = nn.Linear(n_factors*2, nh)
        self.lin2 = nn.Linear(nh, 1)
        self.drop1 = nn.Dropout(p1)
        self.drop2 = nn.Dropout(p2)
        
    def forward(self, cats, conts):
        users,movies = cats[:,0],cats[:,1]
        x = self.drop1(torch.cat([self.u(users),self.m(movies)], dim=1))
        x = self.drop2(F.relu(self.lin1(x)))
        return F.sigmoid(self.lin2(x)) * (max_rating-min_rating+1) + min_rating-0.5

wd=1e-5
model = EmbeddingNet(n_users, n_movies).cuda()
opt = optim.Adam(model.parameters(), 1e-3, weight_decay=wd)

fit(model, data, 3, opt, F.mse_loss)

set_lrs(opt, 1e-3)

fit(model, data, 3, opt, F.mse_loss)

