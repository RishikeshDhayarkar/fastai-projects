# -*- coding: utf-8 -*-
"""bears.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YAnFJDZWwUYAh8q-gcmCIWkLdfN8DP6s
"""

from fastai import *
from fastai.vision import *

from google.colab import drive
drive.mount('/content/drive')

path = Path('drive/My Drive')

path.ls()

dest = path/'bears/teddy'

dest.ls()

file = 'bears/teddy/teddys.txt'

download_images(urls=path/file, dest=dest, max_pics=300)

classes = ['teddy','grizzly','black']

mod_path = path/'bears'

for c in classes:
    print(c)
    verify_images(mod_path/c, delete=True, max_size=500)

bears_path = path/'bears'

np.random.seed(42)
data = ImageDataBunch.from_folder(bears_path, train=".", valid_pct=0.2,
        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)

data

data.classes

data.show_batch(rows=3, figsize=(5,5))

learn = cnn_learner(data, models.resnet50, metrics=error_rate)

learn.fit_one_cycle(4)

learn.save('bears_stage_1')

learn.unfreeze()

learn.lr_find()

learn.recorder.plot()

learn.load('bears_stage_1')
learn.fit_one_cycle(2, max_lr=slice(3e-5, 3e-4))

learn.save('bears_stage_2')

learn.load('bears_stage_2')

interpretation = ClassificationInterpretation.from_learner(learn)

interpretation.plot_confusion_matrix()

path

bears_path

img = open_image(bears_path/'testing/Grizzly-bear_test.jpg')

img.show(size=(5,5))

classes = ['black', 'grizzly', 'teddy']

data2 = ImageDataBunch.single_from_classes(bears_path, classes, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)

learn = cnn_learner(data2, models.resnet50)

learn.load('bears_stage_2')

pred_class, pred_idx, pred_outputs = learn.predict(img)

pred_class

"""<h2>Learning rates and epochs</h2>

Very high learning rate
"""

learn = cnn_learner(data, models.resnet50, metrics=error_rate)

learn.fit_one_cycle(1, max_lr=0.5)

"""Very low learning rate"""

learn = cnn_learner(data, models.resnet50, metrics=error_rate)

learn.fit_one_cycle(5, max_lr=1e-5)

learn.recorder.plot_losses()

"""Less number of epochs"""

learn = cnn_learner(data, models.resnet34, metrics=error_rate, pretrained=False)

learn.fit_one_cycle(1)

"""More number of epochs--> Trying to overfit the model"""

np.random.seed(42)
data = ImageDataBunch.from_folder(bears_path, train=".", valid_pct=0.9, bs=32, 
        ds_tfms=get_transforms(do_flip=False, max_rotate=0, max_zoom=1, max_lighting=0, max_warp=0
                              ),size=224, num_workers=4).normalize(imagenet_stats)

learn = cnn_learner(data, models.resnet50, metrics=error_rate, ps=0, wd=0)
learn.unfreeze()

learn.fit_one_cycle(40, slice(1e-6,1e-4))

"""trainloss > validationloss -- underfitting(train some more by increasing the number of epochs or by increasing the learning rate.

trainloss < validation loss -- overfitting
Reduce the number of epochs 

trainloss = validation loss gives the perfect model
"""

